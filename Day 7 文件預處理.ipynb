{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Day 7: 文件預處理"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "首先，我從我的一個網站中截下一段HTML："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = '''\n",
    " <body>\n",
    "    <!-- JavaScript plugins (requires jQuery) -->\n",
    "    <script src=\"http://code.jquery.com/jquery.js\"></script>\n",
    "    <!-- Include all compiled plugins (below), or include individual files as needed -->\n",
    "    <script src=\"js/bootstrap.min.js\"></script>\n",
    "\n",
    "    <div class=\"container\">\n",
    "        <div class=\"page-header\">\n",
    "            <h3>About Me</h3>\n",
    "        </div>\n",
    "        <div class=\"page-info\">\n",
    "\n",
    "A web developer with experience in a variety of exciting projects, with the most up-to-date and relevant programming foundations available. My wide experience in\n",
    "a diversity of technologies guides me with the best way to get your business success.\n",
    "My interest in academic leads me to research in the field of NLP(Natural Language \n",
    "Processing). Other than the knowledge in CS/IT, I'm also a broad learner who loves \n",
    "to read each and every kind of books.\n",
    "        </div>\n",
    "    </div>\n",
    "</body>\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "我們可以透過正規表示法來移除HTML標籤："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "About Me\n",
      "        \n",
      "        \n",
      "\n",
      "A web developer with experience in a variety of exciting projects, with the most up-to-date and relevant programming foundations available. My wide experience in\n",
      "a diversity of technologies guides me with the best way to get your business success.\n",
      "My interest in academic leads me to research in the field of NLP(Natural Language \n",
      "Processing). Other than the knowledge in CS/IT, I'm also a broad learner who loves \n",
      "to read each and every kind of books.\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "text = re.sub(\"<[^>]+>\", \"\", text).strip()\n",
    "print(text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "我們可以清楚地看到，在標題(About)和文字之間有一些跳行符號。在我們進行記號化(Tokenize)之前，讓我們先把這些跳行符號取代成空格吧。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A web developer with experience in a variety of exciting projects, with the most up-to-date and relevant programming foundations available. My wide experience in a diversity of technologies guides me with the best way to get your business success. My interest in academic leads me to research in the field of NLP(Natural Language  Processing). Other than the knowledge in CS/IT, I'm also a broad learner who loves  to read each and every kind of books.\n"
     ]
    }
   ],
   "source": [
    "text = text.split(\"\\n\\n\")[1].replace(\"\\n\", \" \")\n",
    "print(text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "接著，我們可以把文件分割成句子。雖然用過Python的朋友都知道可以單純的用.split()來處理現在這個例子，但我們還是試著用NLTK提供的句子分割器，為了因應未來可能要處理之更難的文字。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['A web developer with experience in a variety of exciting projects, with the most up-to-date and relevant programming foundations available.', 'My wide experience in a diversity of technologies guides me with the best way to get your business success.', 'My interest in academic leads me to research in the field of NLP(Natural Language  Processing).', \"Other than the knowledge in CS/IT, I'm also a broad learner who loves  to read each and every kind of books.\"]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /Users/hyhu/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('punkt')\n",
    "sent_segmenter = nltk.data.load('tokenizers/punkt/english.pickle')\n",
    "\n",
    "sentences = sent_segmenter.tokenize(text)\n",
    "print(sentences)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "除了分割器，NLTK也能幫助字詞記號化。我們將範例文件中的第一個句子分別用python split和NLTK透過正規表示法寫出來的記號器做個比較吧！"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['A', 'web', 'developer', 'with', 'experience', 'in', 'a', 'variety', 'of', 'exciting', 'projects', ',', 'with', 'the', 'most', 'up', '-', 'to', '-', 'date', 'and', 'relevant', 'programming', 'foundations', 'available', '.']\n",
      "['A', 'web', 'developer', 'with', 'experience', 'in', 'a', 'variety', 'of', 'exciting', 'projects,', 'with', 'the', 'most', 'up-to-date', 'and', 'relevant', 'programming', 'foundations', 'available.']\n"
     ]
    }
   ],
   "source": [
    "word_tokenizer = nltk.tokenize.regexp.WordPunctTokenizer()\n",
    "\n",
    "tokenized_sentence = word_tokenizer.tokenize(sentences[0])\n",
    "print(tokenized_sentence)\n",
    "print(sentences[0].split(\" \"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "NLTK記號器能夠正確地將逗點和\"up-to-date\"這樣的自分割出來。當然，這樣的功能有時候是幫助我們的，在一些應用上這功能反而不是我們所希望發生的。\n",
    "\n",
    "接著，我們來測試Lemmatization。NLTK也有lemmatizer，在使用時上通常會需要先知道句子的詞性標注。在這個範例中，我們簡化這流程，先將輸入的文字用動詞來lemmatize，若發現文字沒有發生變化，我們再用名詞的lemmatizer來試試看。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to /Users/hyhu/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['A', 'web', 'developer', 'with', 'experience', 'in', 'a', 'variety', 'of', 'excite', 'project', ',', 'with', 'the', 'most', 'up', '-', 'to', '-', 'date', 'and', 'relevant', 'program', 'foundation', 'available', '.']\n"
     ]
    }
   ],
   "source": [
    "nltk.download('wordnet')\n",
    "lemmatizer = nltk.stem.wordnet.WordNetLemmatizer()\n",
    "\n",
    "def lemmatize(word):\n",
    "    lemma = lemmatizer.lemmatize(word,'v')\n",
    "    if lemma == word:\n",
    "        lemma = lemmatizer.lemmatize(word,'n')\n",
    "    return lemma\n",
    "\n",
    "print([lemmatize(token) for token in tokenized_sentence])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "現在我們也來試試看Stemming，我們使用NLTK內建的Porter Stemmer："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['A', 'web', 'develop', 'with', 'experi', 'in', 'a', 'varieti', 'of', 'excit', 'project', ',', 'with', 'the', 'most', 'up', '-', 'to', '-', 'date', 'and', 'relev', 'program', 'foundat', 'avail', '.']\n"
     ]
    }
   ],
   "source": [
    "stemmer = nltk.stem.porter.PorterStemmer()\n",
    "print([stemmer.stem(token) for token in tokenized_sentence])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "大家可以觀察看看，在進行lemmatization和stemming之前的文字和之後的文字分別有哪些變化！"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
